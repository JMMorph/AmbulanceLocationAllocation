{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "93633081",
   "metadata": {},
   "source": [
    "# Obtención de las posibles ubicaciones de las ambulancias\n",
    "En este cuaderno de python se implementa la metodología para clasificar los ejes viales que son candidatos para ser puntos de preparación en incidentes con víctimas masivas. Los requisitos previos para ejecutar el cuaderno son:\n",
    "\n",
    "*   Bibliotecas: geopandas, NetworkX, OSMNX, shapely\n",
    "*   Archivos: graph_transport.graphml, es el grafo de transporte previamente descargado de OpenStreetMaps en formato graphml\n",
    "\n",
    "Con este cuaderno se genera el archivo `PLTBs.gpkg` con los resultados de las diferentes etapas de la metodología, separadas en las siguientes capas:\n",
    "\n",
    "*   `filtro_tipo`: Contiene las vialidades del grafo de transporte filtradas por sus características\n",
    "*   `filtro_capacidad`: Contiene las vialidades filtradas por tipo ahora filtradas por capacidad\n",
    "*   `PLTBs`: Contiene las vialidades aptas para ser bases temporales de ambulancias, agrupadas sin sobreposición\n",
    "*   `PLTBs_grouped`: Contiene las vialidades aptas agrupadas por proximidad\n",
    "\n",
    "Cada una de estas capas está dividida en aristas y vértices, con los sufijos `_edges` y `_nodes` respectivamente. En las ultimas dos capas, las aristas corresponden a la geometría de las vialidades agrupadas, mientras que los vértices representan el punto de partida de las ambulancias colocadas en cualquier punto de las vialidades en ese grupo.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a83667c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bibliotecas de uso específico en el cuaderno\n",
    "from shapely.geometry import MultiLineString, Point\n",
    "from copy import deepcopy as copy\n",
    "from collections import deque\n",
    "\n",
    "# Bibliotecas de uso general en el cuaderno\n",
    "from myutils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "733d04d8",
   "metadata": {},
   "source": [
    "## Etapa 1: Selección por características\n",
    "\n",
    "En esta sección identifican las vialidades candidatas a partir del grafo de transporte según sus características; para esto se siguen los siguientes pasos:\n",
    "\n",
    "Crea una copia $G_1$ del grafo de transporte $G_T$, del cual se eliminarán las vialidades no aptas \n",
    "\n",
    "Para cada arista (u,v) del grafo $G_1$:\n",
    "\n",
    "Obten el tipo y sentido de la vialidad\n",
    "*   Si tiene múltiples tipos de vialidad (fue simplificada previamente), toma el tipo de menor jerarquía.\n",
    "*   Si el tipo de vialidad es una incorporación, una carretera o no está clasificada, elimina la arista (u,v).\n",
    "*   De lo contrario:\n",
    "    *   Si se tiene información sobre el número de carriles:\n",
    "        *   Se toma el número de carriles, o el valor mínimo en caso de contar con múltiples valores.\n",
    "        *   Elimina la arista (u,v) si tiene menos de 3 carriles ó tiene menos de 4 pero es residencial o de doble sentido.\n",
    "    *   Si no se tiene:\n",
    "        *   Elimina la arista si es de tipo residencial o terciaria.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb988b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga el grafo de la red de transporte de la Ciudad de México\n",
    "g = ox.load_graphml(filepath=\"../GeoData/graph_transport.graphml\")\n",
    "print('Grafo de transporte cargado')\n",
    "output_file = r'../GeoData/PLTBs_test.gpkg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e9fa02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crea una copia para filtrar el grafo\n",
    "g1 = g.copy()\n",
    "\n",
    "# descarta viaildades de tipo unclassified, residential y motorway\n",
    "discard = set(['unclassified','motorway'])\n",
    "# jerarquía de vialidades\n",
    "hierarchy = {'unclasified':0, 'residential':1, 'tertiary_link':2, 'tertiary':3, 'secondary_link':4, 'secondary':5, 'primary_link':6, 'primary':7, 'trunk_link':8, 'trunk':9, 'motorway_link':10, 'motorway':11}\n",
    "\n",
    "\n",
    "# Elimina vialidades con menos de 3 carriles y que sean incorporaciones\n",
    "for u, v, k, data in g.edges(keys=True, data=True):\n",
    "        \n",
    "    highway = data.get('highway', '')\n",
    "    oneway = data.get('oneway', False)\n",
    "    \n",
    "    # Si highway es una lista, se toma el valor mínimo de la lista\n",
    "    if type(highway) == list:\n",
    "        highway = min(highway, key=lambda x: hierarchy.get(x, 0))\n",
    "    \n",
    "    # Si el tipo de vialidad es un link (incorporación) o es una vialidad que se desea descartar, se elimina la arista\n",
    "    if 'link' in highway or highway in discard:\n",
    "        g1.remove_edge(u, v, k)\n",
    "    \n",
    "    # De lo contrario, se revisa el número de carriles\n",
    "    else:\n",
    "        \n",
    "        # Si se tiene el número de carriles, se toma directamente\n",
    "        if 'lanes' in data:\n",
    "            \n",
    "            lanes = data.get('lanes')\n",
    "            \n",
    "            # Si lanes es una lista, se toma el valor mínimo de la lista\n",
    "            if type(lanes) == list:\n",
    "                lanes = min(lanes)   \n",
    "            \n",
    "            # Si el número de carriles es menor a 3, o si es residencial o de doble sentido y son menos de 4 carriles, se elimina la arista\n",
    "            if lanes < '3' or ( lanes < '4' and (oneway == False  or highway == 'residential' ) ) :\n",
    "                g1.remove_edge(u, v, k)\n",
    "        \n",
    "        # Si no se tiene el número de carriles, se toma el tipo de vialidad\n",
    "        else:\n",
    "            \n",
    "            if highway == 'tertiary' or highway == 'residential':\n",
    "                g1.remove_edge(u, v, k)\n",
    "        \n",
    "print('Grafo filtrado por número de carriles y vialidad')\n",
    "print(len(list(g1.nodes())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6396f2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elimina nodos aislados\n",
    "isolated_nodes = list(nx.isolates(g1))\n",
    "g1.remove_nodes_from(isolated_nodes)\n",
    "\n",
    "print('Grafo simplificado por tipo de vialidad y número de carriles')\n",
    "print(len(list(g1.nodes())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9da857",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = ox.plot_graph(g,\n",
    "                        edge_linewidth = 0.2, \n",
    "                        node_color = (0,0,0,0),\n",
    "                        node_size = 0,\n",
    "                        dpi = 72,\n",
    "                        figsize=(16, 16),\n",
    "                        show=False)\n",
    "\n",
    "ox.plot_graph(g1,\n",
    "                edge_linewidth = 0.2, \n",
    "                edge_color = (0,0.5,0.9,1),\n",
    "                node_color = (0,0.5,0.9,1),\n",
    "                node_size = 1,\n",
    "                dpi = 72,\n",
    "                figsize=(16, 16),\n",
    "                ax=ax)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b8f539d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guarda el grafo filtrado en un archivo .geopackage\n",
    "save_graph_geopackage(g1, filepath=output_file, layer = 'filter_features', directed=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "405af564",
   "metadata": {},
   "source": [
    "## Etapa 2: Selección de vialidades por capacidad\n",
    "\n",
    "Posteriormente se seleccionan únicamente las vialidades que tienen una capacidad para almacenar más de `$n$` ambulancias (un hiper parámetro que define el usuario). La razón por la cual se implementa este procedimiento en una etapa diferente, es que el grafo resultante anterior contiene vialidades \"transitables\" por las ambulancias, y estas vialidades se pueden considerar para agrupar los puntos en etapas posteriores, es decir, aunque no se puedan usar como una base temporal, sí pueden ser transitadas fácilmente por las ambulancias para llegar a otra vialidad que sí es candidata, lo que resulta de utilidad para el proceso de agrupación por proximidad. \n",
    "\n",
    "Los hiper parámetros que se deben definir para esta etapa son:\n",
    "*   `ĺength_ambulance`: es la longitud promedio de una ambulancia, en este caso se consideran 6 metros.\n",
    "*   `min_length`: es la cantidad mínima de ambulancias que debe ser capaz de contener una base temporal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d8020c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parámetros para la reducción\n",
    "length_ambulance = 6 # metros\n",
    "\n",
    "# Elimina aristas con poca capacidad\n",
    "minimum_capacity = 15 # mínima cantidad de vehículos\n",
    "min_length = minimum_capacity* length_ambulance # longitud mínima de la arista\n",
    "\n",
    "\n",
    "g2 = g1.copy()\n",
    "\n",
    "edges_to_remove = []\n",
    "for u, v, k, data in g2.edges(keys=True, data=True):\n",
    "    if data.get('length', 0) < min_length:\n",
    "        edges_to_remove.append((u, v, k))\n",
    "\n",
    "g2.remove_edges_from(edges_to_remove)\n",
    "\n",
    "# Elimina nodos aislados\n",
    "isolated_nodes = list(nx.isolates(g2))\n",
    "g2.remove_nodes_from(isolated_nodes)\n",
    "print(len(list(g2.nodes())))\n",
    "save_graph_geopackage(g2, filepath=output_file, layer = 'filter_capacity', directed=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e559e9cc",
   "metadata": {},
   "source": [
    "### Obtiene los nodos finales de las vialidades resultantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940c26d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "registers = {}\n",
    "registered = set()\n",
    "\n",
    "# Función para asegurar que un dato sea una lista\n",
    "enlist = lambda x: x if type(x) == list else [x]\n",
    "\n",
    "for u, v, k, data in g2.edges(keys=True, data=True):\n",
    "    v_point = g2.nodes[v]\n",
    "    u_point = g2.nodes[u]\n",
    "    segments = data['osmid']\n",
    "\n",
    "    nombre = enlist( data['name'] if 'name' in data else 'Sin nombre')\n",
    "    vialidad = enlist( data['highway'] if 'highway' in data else 'unclassified')\n",
    "    sentido = enlist( data['oneway'] if 'oneway' in data else None)\n",
    "    \n",
    "    largo = data['length'] if 'length' in data else 0\n",
    "    capacidad = data['length']/length_ambulance if 'length' in data else 0\n",
    "\n",
    "    geom_point = [v_point['x'], v_point['y']]\n",
    "    \n",
    "    if 'geometry' in data:\n",
    "        geom_line = [i for i in data['geometry'].coords]\n",
    "\n",
    "    else:\n",
    "        geom_line = [(u_point['x'], u_point['y']), (v_point['x'], v_point['y'])]\n",
    "    \n",
    "    \n",
    "    new_reg = { 'y' : v_point['y'],\n",
    "                'x': v_point['x'],\n",
    "                'lon': v_point['lon'],\n",
    "                'lat': v_point['lat'],\n",
    "                'node': v,\n",
    "                'merged': 1,\n",
    "                't_length': largo,\n",
    "                't_capacity': capacidad,\n",
    "                'length': [largo],\n",
    "                'capacity': [capacidad],\n",
    "                'streets': nombre,\n",
    "                'oneway': sentido,\n",
    "                'grouped': [u],\n",
    "                # 'geom_point' : \"POINT (\"+str(point_geo[0])+\" \"+str(point_geo[1])+\")\"}\n",
    "                'geom_point' : geom_point,\n",
    "                'geom_line' : [geom_line] }\n",
    "    \n",
    "    if v in registered:\n",
    "        \n",
    "        previous = registers[v]\n",
    "\n",
    "        # Numeric attributes\n",
    "        new_reg['merged'] = previous['merged'] + 1\n",
    "        new_reg['t_length'] = previous['t_length'] + new_reg['t_length']\n",
    "        new_reg['t_capacity'] = previous['t_capacity'] + new_reg['t_capacity']     \n",
    "        \n",
    "        # Other attributes\n",
    "        new_reg['streets'] = previous['streets'] + new_reg['streets']      \n",
    "        new_reg['length'] = previous['length'] + new_reg['length']\n",
    "        new_reg['capacity'] = previous['capacity'] + new_reg['capacity']\n",
    "        new_reg['oneway'] = previous['oneway'] + new_reg['oneway']\n",
    "        new_reg['grouped'] = previous['grouped'] + new_reg['grouped']\n",
    "        new_reg['geom_line'] = previous['geom_line'] + new_reg['geom_line']\n",
    "        \n",
    "    registers[v] = new_reg\n",
    "    registered.add(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5226ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crea un dataframe con los registros\n",
    "df = pd.DataFrame.from_records([i for i in registers.values()],index='node')\n",
    "df['geom_point'] = df['geom_point'].apply(lambda x: Point(x[0],x[1]))\n",
    "df['geom_line'] = df['geom_line'].apply(lambda x: MultiLineString(x))\n",
    "\n",
    "# Serializa los datos de tipo lista\n",
    "df['streets'] = df['streets'].apply(lambda x: json.dumps(x, ensure_ascii=False))\n",
    "df['oneway'] = df['oneway'].apply(json.dumps)\n",
    "df['length'] = df['length'].apply(json.dumps)\n",
    "df['capacity'] = df['capacity'].apply(json.dumps)\n",
    "df['grouped'] = df['grouped'].apply(json.dumps)\n",
    "\n",
    "# Almacena los datos en un archivo geopackage\n",
    "bases_puntos = gpd.GeoDataFrame(df.loc[:, df.columns != 'geom_line'], crs=\"EPSG:6369\", geometry = 'geom_point')\n",
    "bases_puntos.to_file(output_file, layer='filter_overlaps_nodes', driver=\"GPKG\", encoding='utf-8')\n",
    "\n",
    "bases_lineas = gpd.GeoDataFrame(df.loc[:, df.columns != 'geom_point'], crs=\"EPSG:6369\", geometry = 'geom_line')\n",
    "bases_lineas.to_file(output_file, layer='filter_overlaps_edges', driver=\"GPKG\", encoding='utf-8')\n",
    "\n",
    "print(f'{len(registers)} vialidades registradas sin sobreposición')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "999dd9b5",
   "metadata": {},
   "source": [
    "## Etapa 3: Agrupamiento por proximidad\n",
    "\n",
    "En esta etapa se agrupan las bases obtenidas de la etapa anterior según un grado de proximidad, para ello se definen los hiperparámetros:\n",
    "\n",
    "*   `minimum_speed`: es la velocidad mínima a la que una ambulancia podría transitar de una base a otra.\n",
    "*   `connect_time`: es el tiempo máximo permitido para trasladarse de una base a otra.\n",
    "\n",
    "El algoritmo al final agrupa y selecciona los nodos representativos de los grupos de forma que garantiza que podría llegar desde éste nodo representativo hasta cualquier otro nodo del mismo grupo en menos de `$t$` minutos, por lo cual se pueden usar los nodos representativos como PLTBs.\n",
    "\n",
    "Otra forma de usar este algoritmo es con el grafo inverso, en el que los grupos formados representan a las vialidades de las cuales se puede llegar al nodo representativo en menos de `$t$` minutos. En esta implementación se optó por esta opción."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22409bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definición de parámetros para la agrupación de vialidades\n",
    "minimum_speed = 20 # velocidad mínima en km/h\n",
    "connect_time = 2 # tiempo de conexión en minutos\n",
    "connect_distance = round((20*1000)/60 * connect_time) # distancia de conexión en metros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63278bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para recorrer el grafo con dfs\n",
    "\n",
    "def dfs_reverse(graph, set_nodes, start_node, lmax):\n",
    "    visited = set()\n",
    "    stack = [(start_node, 0, 0)]  # Tupla de (nodo, profundidad)\n",
    "    depth_dict = {}  # Diccionario para almacenar la profundidad de cada nodo\n",
    "\n",
    "    while stack:\n",
    "        node, depth, length = stack.pop()\n",
    "\n",
    "        if node not in visited :\n",
    "            visited.add(node)\n",
    "            \n",
    "            if node in set_nodes:\n",
    "                depth_dict[node] = depth  # Almacenar la profundidad del nodo\n",
    "                \n",
    "            neighbors = list(graph.predecessors(node))  # Obtener vecinos en dirección contraria\n",
    "            \n",
    "            for neighbor in neighbors:\n",
    "                \n",
    "                # data = graph.get_edge_data(*(node,neighbor, 0)) # Cuando todas las aristas tienen una sola llave que es 0\n",
    "                data = list(graph.get_edge_data(neighbor,node).values())[0] # Cuando las aristas tienen más de una llave\n",
    "                edge_length = data['length']\n",
    "                \n",
    "                # si está a una distancia menor:\n",
    "                if length + edge_length < lmax : \n",
    "                    \n",
    "                    if neighbor not in visited:\n",
    "                        stack.append((neighbor, depth + 1, length + edge_length)) # Incrementar la profundidad en cada nivel\n",
    "\n",
    "    return depth_dict\n",
    "\n",
    "\n",
    "# Función para recorrer el grafo con bfs\n",
    "def bfs(graph_transport, suitable_nodes, start, lmax):\n",
    "    \n",
    "    # Nodos visitados\n",
    "    visited = set()\n",
    "    \n",
    "    # Grupos creados\n",
    "    groups = []\n",
    "    grouped = []\n",
    "    total_nodes_grouped = 0\n",
    "    \n",
    "    # Nodos que no han sido agrupados\n",
    "    others = deque([start]) \n",
    "    \n",
    "    # Mientras haya nodos que no han sido agrupados\n",
    "    while others:\n",
    "        \n",
    "        # Tomar el primer nodo de la lista de nodos no agrupados\n",
    "        head = others.popleft()\n",
    "        \n",
    "        # Si el nodo no ha sido visitado\n",
    "        if head not in visited:\n",
    "            \n",
    "            # Agregar el nodo a los visitados\n",
    "            visited.add(head)\n",
    "            \n",
    "            # Crear una cola del grupo con el nodo como cabeza\n",
    "            queue = deque([ [head, 0] ])\n",
    "\n",
    "            # Crear un grupo con el nodo como cabeza\n",
    "            group = [head]\n",
    "            \n",
    "            # Mientras haya nodos en la cola de ese grupo\n",
    "            while queue:\n",
    "                \n",
    "                # Tomar el primer nodo de la cola, su grado y su longitud acumulada\n",
    "                node, cum_len = queue.popleft()\n",
    "                # node_degree = graph_transport.nodes[node]['street_count']\n",
    "                node_degree = len(set(list(graph_transport.successors(node))).intersection(suitable_nodes))\n",
    "                \n",
    "                # Obtener los vecinos del nodo\n",
    "                neighbors = list(graph_transport.successors(node))\n",
    "                \n",
    "                # Para cada vecino\n",
    "                for neighbor in neighbors:\n",
    "                    \n",
    "                    # Obtener la longitud de la arista\n",
    "                    # data = graph.get_edge_data(*(node,neighbor, 0)) # Cuando todas las aristas tienen una sola llave que es 0\n",
    "                    data = list(graph_transport.get_edge_data(node,neighbor).values())[0] # Cuando las aristas tienen más de una llave\n",
    "                    edge_length = data['length']\n",
    "                    \n",
    "                    # Grado del vecino considerando solo vecinos candidatos\n",
    "                    # neighbor_degree = len(set(list(graph_transport.successors(neighbor))).intersection(suitable_nodes))\n",
    "                    neighbor_degree = len(set(list(graph_transport.successors(neighbor))).intersection(suitable_nodes))\n",
    "\n",
    "                    # Si el vecino no ha sido visitado\n",
    "                    if (neighbor not in visited):\n",
    "                        \n",
    "                        # Si la longitud acumulada es menor a la longitud máxima y una de dos:\n",
    "                        # o el vecino no es candidato, o sí es candidato pero su grado es menor o igual al grado del nodo anterior\n",
    "                        if(cum_len + edge_length < lmax) and ( (neighbor_degree <= node_degree and neighbor in suitable_nodes)  or neighbor not in suitable_nodes):\n",
    "                            \n",
    "                            # Agregar el vecino a la cola del grupo actual\n",
    "                            queue.append([neighbor, cum_len + edge_length])\n",
    "                            \n",
    "                            # Agregar el vecino al grupo actual si es candidato\n",
    "                            if neighbor in suitable_nodes:\n",
    "                                group.append(neighbor)\n",
    "                            \n",
    "                            # Agregar el vecino a los visitados\n",
    "                            visited.add(neighbor)\n",
    "                            \n",
    "                            \n",
    "                        # Si no se cumple alguna de las condiciones anteriores, no se puede agrupar en ese grupo\n",
    "                        else:\n",
    "                            # Agregar el vecino a la lista de nodos no agrupados si es candidato\n",
    "                            if neighbor in suitable_nodes:\n",
    "                                others.append(neighbor)\n",
    "                            \n",
    "            # Agregar el grupo a la lista de grupos\n",
    "            grouped += group\n",
    "            groups.append(copy(group))\n",
    "            total_nodes_grouped += len(group)\n",
    "    \n",
    "    # Regresar los grupos y los nodos agrupados\n",
    "    return groups, grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b773a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializar variables\n",
    "suitable_nodes = set(list(registers.keys()))\n",
    "remaining_nodes = set(list(registers.keys()))\n",
    "subgraphs = []\n",
    "inversed_graph = g1.reverse()\n",
    "\n",
    "# Mientras haya nodos que no han sido agrupados\n",
    "while remaining_nodes:\n",
    "    \n",
    "    # Identifica nodos aún disponibles\n",
    "    suitable_nodes=copy(remaining_nodes)\n",
    "    \n",
    "    # Selecciona un nodo para comenzar el algoritmo\n",
    "    current_node = remaining_nodes.pop()\n",
    "\n",
    "    # Realizar el recorrido DFS inverso y obtener la profundidad de cada vecino\n",
    "    predecessors_nodes = dfs_reverse(inversed_graph, copy(suitable_nodes), copy(current_node), connect_distance)\n",
    "    predecessors_list = list(predecessors_nodes)\n",
    "\n",
    "    # Encuentra el vecino más lejano que puede llegar al nodo\n",
    "    farthest_predecessor = copy(max(predecessors_list, key=lambda x: predecessors_nodes[x]))\n",
    "    \n",
    "    # Realizar el recorrido BFS y obtener los grupos \n",
    "    groups, grouped = bfs(inversed_graph, copy(suitable_nodes), farthest_predecessor, connect_distance)\n",
    "    \n",
    "    \n",
    "    # Actualizar los nodos disponibles\n",
    "    remaining_nodes = remaining_nodes.difference(grouped)\n",
    "    \n",
    "    # Agregar los grupos a la lista de grupos\n",
    "    subgraphs += groups\n",
    "\n",
    "print('total de grupos: ',len(subgraphs))\n",
    "print('total de agrupados: ', sum([len(i) for i in subgraphs]))\n",
    "print('Disponibles originales: ', len(registers))\n",
    "print('faltantes de grupo: ',len(registers) - sum([len(i) for i in subgraphs]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde6b834",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crea los grupos en un dataframe\n",
    "# Copia los registros ya obtenidos\n",
    "registers_grouped = copy(dict(registers))\n",
    "\n",
    "# Por cada grupo\n",
    "for group in subgraphs:\n",
    "    \n",
    "    # Si el grupo tiene más de un elemento\n",
    "    if len(group) > 1:\n",
    "        \n",
    "        # Selecciona el primer nodo como nodo principal\n",
    "        head_node = group[0]\n",
    "\n",
    "        # Por cada nodo en el grupo\n",
    "        for node in group[1::]:\n",
    "            \n",
    "            # Si el nodo ya está en los registros, se fusionan los datos\n",
    "            if node in registers_grouped:\n",
    "                main_reg = dict(registers_grouped[head_node])\n",
    "                new_reg = dict(registers_grouped[node])\n",
    "\n",
    "                # Atributos numéricos\n",
    "                main_reg['merged'] = main_reg['merged'] + new_reg['merged']\n",
    "                main_reg['t_length'] = main_reg['t_length'] + new_reg['t_length']\n",
    "                main_reg['t_capacity'] = main_reg['t_capacity']  + new_reg['t_capacity']           \n",
    "                \n",
    "                # Atributos no numéricos\n",
    "                main_reg['streets'] = main_reg['streets'] + new_reg['streets']\n",
    "                main_reg['length'] = main_reg['length'] + new_reg['length']\n",
    "                main_reg['capacity'] = main_reg['capacity'] + new_reg['capacity']\n",
    "                main_reg['oneway'] = main_reg['oneway'] + new_reg['oneway']\n",
    "                main_reg['grouped'] = main_reg['grouped'] + new_reg['grouped']\n",
    "                main_reg['geom_line'] = main_reg['geom_line'] + new_reg['geom_line']\n",
    "\n",
    "                # Se elimina el nodo de los registros\n",
    "                registers_grouped.pop(node)   \n",
    "                \n",
    "                # Se actualiza el nodo principal\n",
    "                registers_grouped[head_node] = main_reg\n",
    "  \n",
    "            else:\n",
    "                print('Error in node :', node)\n",
    "        \n",
    "# Crea un dataframe con los registros agrupados\n",
    "df = pd.DataFrame.from_records([i for i in registers_grouped.values()],index='node')\n",
    "df['geom_point'] = df['geom_point'].apply(lambda x: Point(x[0],x[1]))\n",
    "df['geom_line'] = df['geom_line'].apply(lambda x: MultiLineString(x))\n",
    "\n",
    "# Serializa los datos de tipo lista\n",
    "df['streets'] = df['streets'].apply(lambda x: json.dumps(x, ensure_ascii=False))\n",
    "df['oneway'] = df['oneway'].apply(json.dumps)\n",
    "df['length'] = df['length'].apply(json.dumps)\n",
    "df['capacity'] = df['capacity'].apply(json.dumps)\n",
    "df['grouped'] = df['grouped'].apply(json.dumps)\n",
    "\n",
    "# Almacena los datos en un archivo geopackage\n",
    "bases_puntos = gpd.GeoDataFrame(df.loc[:, df.columns != 'geom_line'], crs=\"EPSG:6369\", geometry = 'geom_point')\n",
    "bases_puntos.to_file(output_file, layer='PLTBs_nodes', driver=\"GPKG\", encoding=\"utf-8\")\n",
    "\n",
    "bases_lineas = gpd.GeoDataFrame(df.loc[:, df.columns != 'geom_point'], crs=\"EPSG:6369\", geometry = 'geom_line')\n",
    "bases_lineas.to_file(output_file, layer='PLTBs_edges', driver=\"GPKG\", encoding=\"utf-8\")\n",
    "\n",
    "print(len(registers_grouped),' PLTBs obtenidos')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qgis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "2a6b1e8eb72f79e0e2464ece4d662328b256caa701fce0e0b6238695d5908f4b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
