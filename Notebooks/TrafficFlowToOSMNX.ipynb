{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from myutils import *\n",
    "import rasterio\n",
    "from rasterio.transform import from_origin\n",
    "import pickle\n",
    "\n",
    "from datetime import datetime\n",
    "from datetime import date\n",
    "\n",
    "import requests\n",
    "import asyncio\n",
    "import aiohttp\n",
    "import time\n",
    "\n",
    "import os\n",
    "import gc\n",
    "\n",
    "from shapely import Point\n",
    "import rasterio\n",
    "from rasterio.merge import merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga el polígono de la ciudad de méxico, aplica un buffer de 100 mts y lo proyecta a WGS84\n",
    "cdmx = gpd.read_file(r'../GeoData/Polygons.gpkg', layer='CDMX', encoding='utf-8')\n",
    "polygon = cdmx.geometry[0].buffer(100)\n",
    "cdmx['geometry'] = polygon\n",
    "cdmx.to_crs(4326, inplace=True)\n",
    "polygon = cdmx.geometry[0]\n",
    "\n",
    "# Obtiene el bounding box del polígono\n",
    "(lon1 , lat1, lon2, lat2) = polygon.bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16, 14678, 29234] [16, 14756, 29129]\n",
      "Teselas totales: 79x106 = 8374\n",
      "Coordenadas reales: [19.04654131204215, -99.371337890625] [19.59601924031249, -98.9373779296875]\n",
      "resolucion en pixeles 1.1943285763263702 metros/pixel\n"
     ]
    }
   ],
   "source": [
    "# Cálculo de la resolución de las teselas\n",
    "\n",
    "# Nivel de zoom\n",
    "zoom = 16\n",
    "\n",
    "# Primera y última tesela\n",
    "lower = lat_lon_to_tile_zxy(lat1, lon1, zoom)\n",
    "upper = lat_lon_to_tile_zxy(lat2, lon2, zoom)\n",
    "\n",
    "# Tamaño de la imagen a descargar (512x512 o 256x256)\n",
    "imsize = int(512)\n",
    "print(lower,upper)\n",
    "\n",
    "# Número de teselas por lado\n",
    "tiles_x = (upper[1] - lower[1] + 1)\n",
    "tiles_y = (lower[2] - upper[2] + 1)\n",
    "print(f'Teselas totales: {tiles_x}x{tiles_y} = {tiles_x*tiles_y}')\n",
    "\n",
    "# Coordenadas en lat, lon de las esquinas de la imagen, en el sistema de referencia WGS84\n",
    "inf_izq = tile_zxy_to_lat_lon(zoom, lower[1], lower[2] + 1)\n",
    "sup_der = tile_zxy_to_lat_lon(zoom, upper[1] + 1, upper[2])\n",
    "sup_izq = (sup_der[0], inf_izq[1])\n",
    "inf_der = (inf_izq[0], sup_der[1])\n",
    "\n",
    "# Cálculo de la resolución de las teselas\n",
    "circunferencia = 40075017\n",
    "resolucion_tiles = circunferencia/(2**zoom) # metros\n",
    "resolucion_pixeles = resolucion_tiles/imsize # metros/pixel\n",
    "\n",
    "print('Coordenadas reales:', inf_izq, sup_der)\n",
    "print('resolucion en pixeles', resolucion_pixeles, 'metros/pixel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Genera la geometría de las teselas\n",
    "tiles_bbox = {'x':[], 'y':[], 'lat':[], 'lon':[], 'geometry':[], 'intersect':[]}\n",
    "\n",
    "# Identifica las teselas que intersectan con el polígono de la ciudad de méxico\n",
    "# para descargar únicamente las teselas que contienen información de la ciudad\n",
    "queries = []\n",
    "\n",
    "# Recorre los índices de las teselas\n",
    "for i in range(lower[1], upper[1]+1):\n",
    "    for j in range(upper[2], lower[2]+1):\n",
    " \n",
    "        y1,x1,y2,x2 = tile_zxy_to_lat_lon_bbox(zoom,i,j)\n",
    "        \n",
    "        point1 = (x1,y1)\n",
    "        point2 = (x1,y2)\n",
    "        point3 = (x2,y2)\n",
    "        point4 = (x2,y1)\n",
    "        \n",
    "        # Genera la geometría de la tesela\n",
    "        tile = sp.Polygon([point1,point2,point3,point4])\n",
    "        \n",
    "        # Almacena la geometría de la tesela\n",
    "        tiles_bbox['lon'].append(i)\n",
    "        tiles_bbox['lat'].append(j)\n",
    "        tiles_bbox['x'].append(x1)\n",
    "        tiles_bbox['y'].append(y1)\n",
    "        tiles_bbox['geometry'].append(tile)\n",
    "        \n",
    "        # Si la tesela intersecta con el polígono de la ciudad de méxico\n",
    "        if tile.intersects(polygon):\n",
    "            \n",
    "            \n",
    "            tiles_bbox['intersect'].append(1)\n",
    "            \n",
    "            # Marca la tesela para descargar\n",
    "            queries.append({'x': i, 'y':j, 'query': 1, 'sup_izq': (y1,x1), 'inf_der': (y2,x2)})\n",
    "        \n",
    "        else:\n",
    "            # Marca la tesela para no descargar\n",
    "            queries.append({'x': i, 'y':j, 'query': 0, 'sup_izq': [], 'inf_der': []})\n",
    "            tiles_bbox['intersect'].append(0)\n",
    "        \n",
    "bbox = sp.Polygon([(inf_izq[1], inf_izq[0]), (sup_der[1], inf_izq[0]), (sup_der[1], sup_der[0]), (inf_izq[1], sup_der[0])])\n",
    "tiles_bbox['x'].insert(0, 0)\n",
    "tiles_bbox['y'].insert(0, 0)\n",
    "tiles_bbox['lat'].insert(0, 0)\n",
    "tiles_bbox['lon'].insert(0, 0)\n",
    "tiles_bbox['intersect'].insert(0, -1)\n",
    "tiles_bbox['geometry'].insert(0, bbox)\n",
    "\n",
    "# Convierte las teselas a un GeoDataFrame\n",
    "tiles_bbox = gpd.GeoDataFrame(tiles_bbox, crs=4326)\n",
    "\n",
    "# Número de teselas a descargar\n",
    "tiles_used = sum([ 1 if i['query'] == 1 else 0 for i in queries])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tiles_bbox.explore(column='intersect', cmap='tab20', tooltip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tiles_bbox.to_file('../GeoData/Traffic/Mini/_tiles_bbox.gpkg', layer='tiles', driver=\"GPKG\", encoding=\"utf-8\")\n",
    "tiles_bbox.to_file('../GeoData/Traffic/Ej/tiles_bbox.gpkg', layer='tiles', driver=\"GPKG\", encoding=\"utf-8\")\n",
    "del(tiles_bbox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para generar la url de descarga de las teselas\n",
    "def get_url(x,y,zoom, imsize, apikey):\n",
    "    url = f'https://api.tomtom.com/traffic/map/4/tile/flow/relative0/{zoom}/{x}/{y}.png?tileSize={imsize}&key=' + apikey\n",
    "    return url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Consulta asíncrona de teselas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtiene la fecha y hora actual\n",
    "fecha = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "\n",
    "# Api key de TomTom\n",
    "try:\n",
    "    # Api key de TomTom\n",
    "    with open('../GeoData/tomtom_apikey.txt', 'r') as f:\n",
    "        apiKey = f.read()\n",
    "        f.close()\n",
    "except:\n",
    "    print('No se pudo leer el archivo con la API key de TomTom')\n",
    "    print('se debe crear un archivo \"tomtom_apikey.txt\" con la API key en: ', '../GeoData/')\n",
    "\n",
    "# Lista para almacenar las imágenes\n",
    "tiles = dict([(i, dict([ (j,'') for j in range(upper[2], lower[2]+1)] )) for i in range(lower[1], upper[1]+1)])\n",
    "attempts = 5\n",
    "failed = []\n",
    "\n",
    "async def get(query, session):\n",
    "    try:\n",
    "        \n",
    "        x = query['x']\n",
    "        y = query['y']\n",
    "        \n",
    "        if query['query'] == 1:\n",
    "            url_query = get_url(query['x'], query['y'], zoom, imsize, apiKey)\n",
    "            \n",
    "            async with session.get(url=url_query) as response:\n",
    "                \n",
    "                if response.status != 200:\n",
    "                    for _ in range(attempts):\n",
    "                        await asyncio.sleep(1)  # Esperar 1 segundo antes de volver a intentar\n",
    "                        \n",
    "                        # Hacer un nuevo intento con la misma URL\n",
    "                        async with session.get(url=url_query) as new_response:\n",
    "                            if new_response.status == 200:\n",
    "                                resp = await new_response.read()\n",
    "                                image = np.array(Image.open(BytesIO(resp)))\n",
    "                                tiles[x][y] = image\n",
    "                                print(f'Imagen obtenida: {x},{y}')\n",
    "                                break  # Si se obtiene una respuesta exitosa, salir del bucle\n",
    "                            \n",
    "                    else:\n",
    "                        print(f'Error al obtener imagen para {x},{y}. Se agotaron los intentos.')\n",
    "                        failed.append(query)\n",
    "                else:\n",
    "                    resp = await response.read()\n",
    "                    image = np.array(Image.open(BytesIO(resp)))\n",
    "                    tiles[x][y] = image\n",
    "                    print(f'Imagen obtenida: {x},{y}')\n",
    "        else:\n",
    "            tiles[x][y] = 0\n",
    "            \n",
    "            \n",
    "    except Exception as e:\n",
    "        print(\"Unable to get url {} due to {}.\".format(query, e.__class__))\n",
    "        \n",
    "\n",
    "async def main(urls):\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        ret = await asyncio.gather(*[get(url, session) for url in urls])\n",
    "    print(f'Finalizado, faltaron {len(failed)} imágenes')\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "result = await main(queries)\n",
    "end = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Consulta secuencial de Tiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# # Api key de TomTom\n",
    "# try:\n",
    "#     # Api key de TomTom\n",
    "#     with open(path + 'tomtom_apikey.txt', 'r') as f:\n",
    "#         apiKey = f.read()\n",
    "#         f.close()\n",
    "# except:\n",
    "#     print('No se pudo leer el archivo con la API key de TomTom')\n",
    "#     print('se debe crear un archivo \"tomtom_apikey.txt\" con la API key en: ', path_source)\n",
    "# images = []\n",
    "\n",
    "# for url in urls:\n",
    "    \n",
    "#     if url['query'] == 1:\n",
    "        \n",
    "#         response = requests.get(url['url'])\n",
    "#         if response.status_code == 200:\n",
    "#             image = np.array(Image.open(BytesIO(response.content)))\n",
    "#             images.append([url['x'], url['y'], image])\n",
    "#             x = url['x']\n",
    "#             y = url['y']\n",
    "#             print(f'Imagen obtenida: {x},{y}, {len(images)}/{tiles_x*tiles_y}')\n",
    "#         else: \n",
    "#             print(\"Fallo en la descarga de la imagen\")\n",
    "    \n",
    "#     else:\n",
    "#         images.append([url['x'], url['y'], np.zeros((imsize,imsize,4))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conversión de tesela a monobanda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rgba_to_mono(tile):\n",
    "    \n",
    "    # Máscara para identificar los pixeles con información\n",
    "    mask = tile[:,:,3] > 250\n",
    "\n",
    "    # Obtener los canales RGB y aplicar la máscara\n",
    "    tile2 = tile[:,:,0:3] * np.expand_dims(mask, axis = 2)\n",
    "    \n",
    "    # Posteriza la imágen a 4 valores por canal\n",
    "    tile2 = tile2/(255/4)\n",
    "    tile2 = tile2.round() * (255/4)\n",
    "    \n",
    "    # Aplica la fórmula 5*R + G + 10*B\n",
    "    res = 5*tile2[...,1] + tile2[...,0] + 10*tile2[...,2]\n",
    "\n",
    "    # Define los colores de la imagen\n",
    "    # colores = [0, 206, 1594, 1913, 1721, 1211, 4335]\n",
    "    colores = [0, 1657, 1848,1530, 212, 1148,  4080  ]\n",
    "    \n",
    "    # Define las tolerancias para cada color\n",
    "    tols = np.array([0, 10, 10, 1, 50, 10, 10])\n",
    "\n",
    "    # Calcula la diferencia entre la imágen y los colores\n",
    "    dif  = np.abs(res - np.expand_dims(colores,axis=[1,2]))\n",
    "    \n",
    "    # Obtiene el índice del color más cercano\n",
    "    ind_min = np.argmin(dif,axis=0).astype(np.intp)\n",
    "    \n",
    "    # Asigna el color más cercano sólo si la diferencia es menor a la tolerancia\n",
    "    ima =  ind_min * (dif.min(axis=0) <= np.expand_dims(tols,axis=[1,2]).take(ind_min))\n",
    "    \n",
    "    return ima.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Guardar el objeto para consulta por tesela"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../GeoData/Traffic/Ej/'\n",
    "name = f'traffic_flow_{zoom}_{fecha}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for q in queries:\n",
    "#     if q['query'] == 1:\n",
    "        \n",
    "#         tiles[q['x']][q['y']] = {'array' : tiles[q['x']][q['y']], \n",
    "#                                  'sup_izq': q['sup_izq'], \n",
    "#                                  'inf_der': q['inf_der']}\n",
    "\n",
    "# ##Para guardar el diccionario con las teselas como RGBA\n",
    "# with open(path + name + '_rgba.pkl', 'wb') as file:\n",
    "#     pickle.dump(tiles, file)\n",
    "#     print(f'Teselas guardadas como \"{path + name}_rgba.pkl\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplica la función para convertir las imágenes a monocromáticas\n",
    "for q in queries:\n",
    "    if q['query'] == 1:\n",
    "        \n",
    "        tiles[q['x']][q['y']] = {'array' : rgba_to_mono(tiles[q['x']][q['y']]), \n",
    "                                 'sup_izq': q['sup_izq'], \n",
    "                                 'inf_der': q['inf_der']}\n",
    "\n",
    "# Para guardar el diccionario con las teselas como imágenes monocromáticas\n",
    "# (sobre escribe la variable tiles, por lo que se recomienda guardar primero las teselas RGBA)\n",
    "with open(path + name + '.pkl', 'wb') as file:\n",
    "    pickle.dump(tiles, file)\n",
    "    print(f'Teselas guardadas como \"{path + name}.pkl\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creación de una imágen completa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para trabajar con las teselas guardadas previamiente en otra sesión\n",
    "# path = '../GeoData/Traffic/Ej/'\n",
    "# name = 'traffic_flow_16_2023-11-14_13-45-00_rgba'\n",
    "# tiles = pickle.load(open(path + name + '.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_geotif(tiles,upper,lower,imsize,zoom,path,name,rgba=False):\n",
    "\n",
    "    ### ----- Creación de filas como raster ----- ###\n",
    "    \n",
    "    # Ruta completa de la carpeta \"temp\" para almacenar los rasters individuales\n",
    "    # de cada fila temporalmente\n",
    "    \n",
    "    ruta_temp = os.path.join(path, \"temp\")\n",
    "\n",
    "    # Verificar si la carpeta \"temp\" existe\n",
    "    if not os.path.exists(ruta_temp):\n",
    "        # Si no existe, crearla\n",
    "        os.makedirs(ruta_temp)\n",
    "    \n",
    "    # Lista para almacenar los nombres de los rasters individuales\n",
    "    filas_temp = []\n",
    "\n",
    "    # Recorre los índices de las filas\n",
    "    for j in range(upper[2], lower[2]+1):\n",
    "        \n",
    "        # Lista para almacenar las teselas de la fila\n",
    "        fila = []\n",
    "        \n",
    "        # Recorre los índices de las columnas\n",
    "        for i in range(lower[1], upper[1]+1):\n",
    "            \n",
    "            # Si la tesela existe, se agrega a la fila\n",
    "            if tiles[i][j]:\n",
    "                # tiles[i][j][0][0] = np.array([0,0,0,255])\n",
    "                # tiles[i][j][-1][-1] = np.array([255,0,0,255])\n",
    "                fila.append(tiles[i][j]['array'].astype(np.uint8))\n",
    "            \n",
    "            # Si no existe, se agrega una tesela vacía\n",
    "            else:\n",
    "                if rgba:\n",
    "                    fila.append(np.zeros((imsize,imsize,4), dtype=np.uint8))\n",
    "                \n",
    "                else:\n",
    "                    fila.append(np.zeros((imsize,imsize), dtype=np.uint8))\n",
    "                \n",
    "        \n",
    "        fila = np.hstack(fila)\n",
    "        \n",
    "        # Calcula las coordenadas en lat, lon de las esquinas de la tesela    \n",
    "        y1, x1, y2, x2 = tile_zxy_to_lat_lon_bbox(zoom,lower[1],j)\n",
    "        x1, x2 = sup_izq[1], sup_der[1]\n",
    "        \n",
    "        # def from_bounds(west, south, east, north, width, height):\n",
    "        transformacion = rasterio.transform.from_bounds(x1,y2,x2,y1,imsize*tiles_x,imsize)\n",
    "        \n",
    "        if rgba:\n",
    "            banda = 4\n",
    "        else:\n",
    "            banda = 1\n",
    "        \n",
    "        row_name = f'{path}temp/row_{j}.tif'\n",
    "        new_dataset = rasterio.open(row_name, 'w', driver='GTiff',\n",
    "                                    height = fila.shape[0], width = fila.shape[1],\n",
    "                                    count=banda, dtype=str(fila.dtype),\n",
    "                                    crs='EPSG:4326',\n",
    "                                    transform=transformacion)\n",
    "\n",
    "        if rgba:\n",
    "            new_dataset.write(np.rollaxis(fila, axis=2) )\n",
    "        else:\n",
    "            # new_dataset.write(np.rollaxis(np.expand_dims(fila,axis=-1), axis=2))\n",
    "            new_dataset.write(fila,1)\n",
    "            \n",
    "        new_dataset.close()\n",
    "        del(new_dataset)\n",
    "        \n",
    "        filas_temp.append(row_name)\n",
    "    \n",
    "    \n",
    "    \n",
    "    ### ----- Combinación de filas en una sola imagen ----- ###\n",
    "\n",
    "    # Cargar los rasters individuales\n",
    "    rasters = []\n",
    "\n",
    "    for ruta_raster in filas_temp:\n",
    "        rasters.append(rasterio.open(ruta_raster) )\n",
    "\n",
    "    # Combinar los rasters en una sola imagen\n",
    "    merged, out_transform = merge(rasters)\n",
    "\n",
    "    # Actualizar la información de georreferenciación si es necesario\n",
    "    out_profile = rasters[0].profile\n",
    "    out_profile.update(transform=out_transform, width=merged.shape[2], height=merged.shape[1])\n",
    "\n",
    "    # Guardar la imagen combinada\n",
    "    with rasterio.open(path+name+'.tif', 'w', **out_profile) as dst:\n",
    "        dst.write(merged)\n",
    "        written = True\n",
    "\n",
    "    if written:\n",
    "        print(f'Imagen guardada como \"{path + name}.tif\"')\n",
    "        # Eliminar los rasters\n",
    "        del(merged)\n",
    "        del(rasters)\n",
    "        for ruta_raster in filas_temp:\n",
    "            os.remove(ruta_raster)\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guarda la imágene como un GeoTiff\n",
    "save_geotif(tiles,upper,lower,imsize,zoom,path,name,rgba=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga el grafo de la red de transporte de la Ciudad de México\n",
    "g = ox.load_graphml(filepath=\"../GeoData/graph_transport.graphml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_nodes, gdf_edges = ox.graph_to_gdfs(g, nodes=True, edges=True, node_geometry=True, fill_edge_geometry=True)\n",
    "# gdf_edges['geometry'] = gdf_edges['geometry'].to_crs(4326)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para obtener el punto medio de una línea\n",
    "def middle_point(geom):\n",
    "    \n",
    "    # Obtiene las coordenadas de los puntos que forman la línea\n",
    "    lats, lons = geom.xy\n",
    "    lats = lats.tolist()\n",
    "    lons = lons.tolist()\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Si la línea tiene dos puntos, 'a' es el punto medio y 'b' es el punto final\n",
    "    if len(lats) == 2:\n",
    "        mid_point = [sum(lats)/2, sum(lons)/2]\n",
    "        a = np.array(mid_point)\n",
    "        b = np.array([lats[1], lons[1]])\n",
    "    \n",
    "    # Si la línea tiene más de dos puntos, 'a' es el punto medio de los dos puntos centrales\n",
    "    # y b es el punto central posterior a 'a'\n",
    "    else:\n",
    "        \n",
    "        middle = int(len(lats)/2)\n",
    "        a = np.array([sum(lats[middle-1:middle+1]), sum(lons[middle-1:middle+1])])/2\n",
    "        b = np.array([lats[middle], lons[middle]])\n",
    "    \n",
    "    # Calcula el vector que va de 'a' a 'b'\n",
    "    vec_ab = b - a\n",
    "    \n",
    "    # Calcula el vector perpendicular a 'ab'\n",
    "    perpendicular = np.array([vec_ab[1], -vec_ab[0]])\n",
    "    \n",
    "    # Normaliza el vector perpendicular y lo traslada al punto 'a', lo desplaza 3 metros\n",
    "    perpendicular = 3*perpendicular/np.linalg.norm(perpendicular)\n",
    "    perpendicular += a\n",
    "    \n",
    "    # Regresa el punto extremo del vector perpendicular\n",
    "    return Point(perpendicular[0], perpendicular[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para muestrar una imagen geo-referenciada a partir de un punto\n",
    "def sample_raster(point, zoom, tiles, imsize, tiles2 = ''):\n",
    "    # Obtiene las coordenadas del punto\n",
    "    lat = point.y\n",
    "    lon = point.x\n",
    "    \n",
    "    # Obtiene las coordenadas de la tesela correspondiente\n",
    "    z, x,y = lat_lon_to_tile_zxy(lat, lon, zoom)\n",
    "    lat1, lon1 = tiles[x][y]['sup_izq']\n",
    "    lat2, lon2 = tiles[x][y]['inf_der']\n",
    "    \n",
    "    # Normaliza las coordenadas, considerando las esquinas van de 0 a imsize\n",
    "    centro_x = math.floor(imsize * (lon - lon1)/(lon2 - lon1))\n",
    "    centro_y = math.floor(imsize * (lat - lat1)/(lat2 - lat1))\n",
    "    \n",
    "    # Pixel correspondiente al centroide\n",
    "    c = [centro_y, centro_x]\n",
    "    \n",
    "    # radio de la ventana\n",
    "    r = 5\n",
    "    window = tiles[x][y]['array'][max(c[0] - r, 0): min(imsize - 1, c[0] + r),\n",
    "                                  max(c[1] - r, 0): min(imsize - 1, c[1] + r)]\n",
    "    \n",
    "    # Cuenta la frecuencia de cada valor en la ventana\n",
    "    vals, counts = np.unique(window, return_counts=True)\n",
    "    \n",
    "    # Si sólo hay un valor, asigna el valor más común\n",
    "    if len(vals) == 1:\n",
    "        most_common = vals[0]\n",
    "        \n",
    "        # Si el valor más común es 0, asigna 1 (libre)\n",
    "        if most_common == 0:\n",
    "            most_common = 1\n",
    "\n",
    "    # Si hay múltiples valores:\n",
    "    else:\n",
    "        \n",
    "        # Encuentra el valor más común en la ventana, sin considerar el 0\n",
    "        most_common = vals[np.argmax(counts[1::]) + 1]\n",
    "    \n",
    "    # Si se adjunta una segunda matriz, asigna el valor más común a la ventana correspondiente\n",
    "    if tiles2:\n",
    "        tiles2[x][y]['array'][max(c[0] - r, 0): min(imsize - 1, c[0] + r),\n",
    "                             max(c[1] - r, 0): min(imsize - 1, c[1] + r)] = most_common\n",
    "    \n",
    "    return most_common\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtiene los puntos medios de las aristas para sacar la muestra\n",
    "gdf_edges['middle_point'] = gdf_edges.apply(lambda row : middle_point(row['geometry']), axis = 1)\n",
    "\n",
    "# Crea un objeto GeoSeries con los puntos medios de las aristas\n",
    "gdf_edges_mid = gdf_edges['middle_point'].copy()\n",
    "gdf_edges_mid.rename('geometry', inplace=True)\n",
    "\n",
    "# Por defecto estan en el sistema de referencia del grafo, por lo que se convierten a WGS84\n",
    "# para poder obtener las teselas correspondientes\n",
    "gdf_edges_mid.crs = gdf_edges.crs\n",
    "gdf_edges_mid = gdf_edges_mid.to_crs(4326)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Crea una copia de las teselas para asignarles el valor de la muestra\n",
    "tiles2 = copy(tiles)\n",
    "traffic_data = gdf_edges_mid.apply(lambda row : sample_raster(row, zoom, tiles, imsize,tiles2=tiles2))\n",
    "traffic_data = pd.DataFrame(traffic_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guarda las teselas con la ventana de muestreo marcada\n",
    "save_geotif(tiles2,upper,lower,imsize,zoom,path,name+\"_sampled\",rgba=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traffic_data.to_pickle(f'{path}{name}_traffic_data.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traffic_data = pd.read_pickle(f'{path}{name}_traffic_data.tar') \n",
    "gdf_edges = gdf_edges.assign(trafico= traffic_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_edges.head()\n",
    "gdf_edges[['trafico']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_g = ox.graph_from_gdfs(gdf_nodes, gdf_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_graph_geopackage(new_g, filepath=f'{path}{name}_graph_traffic.gpkg', encoding='utf-8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para observar en qué punto se hace el muestreo\n",
    "gdf_edges_mid.to_file(path + 'middle_point.gpkg', layer='edges', driver=\"GPKG\", encoding=\"utf-8\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
