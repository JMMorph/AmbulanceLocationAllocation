{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed\n",
    "from optimize import *\n",
    "import time\n",
    "cmap = plt.get_cmap('viridis')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "configuraciones = ['--cr un --mu bf --a ur --rep rm --pop 200 --dec 50 --prob_cr 0.5 --prob_mu 0.25 --prob_ini 0.1',\n",
    "                    '--cr un --mu bf --a ur --rep rm --pop 200 --dec 50 --prob_cr 0.75 --prob_mu 0.5 --prob_ini 0.25',\n",
    "                    '--cr hun --mu bfo --a ur --rep rm --pop 200 --dec 50 --prob_cr 0.5 --prob_mu 0.5 --prob_ini 0.25',\n",
    "                    '--cr un --mu bf --a ur --rep rm --pop 200 --dec 50 --prob_cr 0.5 --prob_mu 0.5 --prob_ini 0.1',\n",
    "                    '--cr un --mu bfo --a ur --rep rm --pop 200 --dec 50 --prob_cr 0.5 --prob_mu 0.5 --prob_ini 0.1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instance_id = '7'\n",
    "instance = '../GeoData/Instances/Instance_' + instance_id + '.pkl'\n",
    "\n",
    "output = 'Results/testPerformance'+instance_id\n",
    "testPerformance = dict([i, {'hv':[], 'res':[], 'time':[]}] for i in range(len(configuraciones)))\n",
    "plot_performance = False\n",
    "plot_time = False\n",
    "plot_performance_multi = True\n",
    "plot_convergence = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Celda para ejecutar el análisis desde cero\n",
    "En esta celda se realizan las 20 ejecuciones de cada configuración para la instancia establecida arriba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    for i,p in enumerate(configuraciones):\n",
    "        \n",
    "        for ejec in range(20):\n",
    "            seed = str(ejec*308)\n",
    "            \n",
    "            # Extra whitespace around options is important!\n",
    "            parameters = ' -i ' + instance + ' --seed ' + seed + ' ' + p\n",
    "\n",
    "            ini = time.time()\n",
    "            hv, res = exec_algorithm(parameters, returnData=True, timeout=10)\n",
    "            fin = time.time()\n",
    "            \n",
    "            testPerformance[i]['hv'].append(hv)\n",
    "            testPerformance[i]['res'].append(res)\n",
    "            testPerformance[i]['time'].append(fin - ini)\n",
    "            \n",
    "            finish = ['ok','fail'][res == -1]\n",
    "            \n",
    "            linea = str(i) + ' ' + str(ejec) + ' ' + str(hv) + ' ' + str(fin - ini) + ' ' + finish + '\\n'\n",
    "            with open(output + '.txt', 'a') as file:\n",
    "                file.write(linea)\n",
    "                \n",
    "            with open(output+'.pkl', 'wb') as f:  \n",
    "                pickle.dump(testPerformance, f)\n",
    "                f.close()\n",
    "            \n",
    "            print(linea)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Celda para cargar el análisis previo\n",
    "PAra no volver a ejecutar desde cero el análisis, se carga la información del archivo pickle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Results/testPerformance' + instance_id+ '.pkl', 'rb') as f:\n",
    "    testPerformance = pickle.load(f) \n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cargar datos de irace\n",
    "En caso de ser de utilidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "irace = pd.read_csv('../ajuste/export/export.csv')\n",
    "irace.pop('Unnamed: 0')\n",
    "\n",
    "ejecs = irace[irace['instancename'] == 'Instance_' + instance_id]\n",
    "ejecs = ejecs[ejecs['type']=='regular']\n",
    "ejecs = ejecs[ejecs['value'] <= 0.99]\n",
    "otras_conf = ejecs['value'].to_list()\n",
    "otras_conf_color = ejecs['id'].to_list()\n",
    "bkv = ejecs['bkv'].to_list()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graficar el desempeño por instancia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if plot_performance:\n",
    "    fig, ax = plt.subplots(figsize=(3, 8))\n",
    "\n",
    "    # Coordenadas x para las barras\n",
    "    ind = len(testPerformance)\n",
    "\n",
    "    # Ancho de las barras\n",
    "    ancho_barra = 0.5\n",
    "\n",
    "    hipervolumenes = [testPerformance[i]['hv'] for i in range(ind)]\n",
    "\n",
    "    tiempos = [np.mean(testPerformance[i]['time']) for i in range(ind)]\n",
    "\n",
    "    ax.boxplot(hipervolumenes,widths=ancho_barra, showfliers=True, zorder = 3, \n",
    "            medianprops=dict(color=(1,0,0,1)), )\n",
    "    # ax.scatter([0]*len(otras_conf), otras_conf, c=otras_conf_color, cmap='viridis', \n",
    "    #            marker='s', zorder = 3, alpha=0.2, linewidths=0, label='Configuraciones regulares')\n",
    "    for i in range(ind):\n",
    "        ax.scatter([i+1]*len(testPerformance[i]['hv']), testPerformance[i]['hv'], \n",
    "                cmap='viridis', marker='x', zorder = 3, alpha=0.2, linewidths=1)\n",
    "\n",
    "    ax.plot([-1,6], [bkv,bkv], '--', color='black', zorder = 0, label='Mejor valor conocido')\n",
    "\n",
    "    # Configuración de ejes y etiquetas\n",
    "    ax.set_xlabel('$Configuración$')\n",
    "    ax.set_ylabel('$Hipervolumen$')\n",
    "    ax.set_title('$Instancia\\ ' + instance_id + '$')\n",
    "    ax.set_xticklabels([f'{i+1}' for i in range(ind)])\n",
    "    ax.set_xlim([0,6])\n",
    "\n",
    "    # Leyenda para identificar los modelos\n",
    "    ax.legend(fancybox=True, shadow=True)\n",
    "    ax.grid(True,zorder=0, color='gray', linestyle='--', linewidth=0.4)\n",
    "    ax.set_ylim([bkv-0.01, np.max(hipervolumenes)+0.01])\n",
    "\n",
    "    fig.savefig('/home/cic/Tesis/Figuras/Results/testPerformance' + instance_id + '.png', dpi=300, bbox_inches='tight')\n",
    "    print(bkv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insts = ['4','7','5']\n",
    "tablas_20 = dict()\n",
    "pf_cmap = plt.get_cmap('viridis')\n",
    "\n",
    "for num,instance_id in enumerate(insts):\n",
    "    instance = '../GeoData/Instances/Instance_' + instance_id + '.pkl'\n",
    "    \n",
    "\n",
    "    with open('Results/testPerformance' + instance_id + '.pkl', 'rb') as f:\n",
    "        testPerformance = pickle.load(f) \n",
    "        f.close()\n",
    "    hipervolumenes = [testPerformance[i]['hv'] for i in range(len(testPerformance))]\n",
    "    min_hv = np.min(hipervolumenes,axis = 1)\n",
    "    max_hv = np.max(hipervolumenes,axis = 1)\n",
    "    mean_hv = np.mean(hipervolumenes,axis = 1)\n",
    "    median_hv = np.median(hipervolumenes,axis = 1)\n",
    "    std_hv = np.std(hipervolumenes,axis = 1)\n",
    "    \n",
    "    data_20 = dict()\n",
    "    data_20['config'] = [i for i in range(len(configuraciones))]\n",
    "    data_20['min'] = min_hv\n",
    "    data_20['máx'] = max_hv\n",
    "    data_20['prom'] = mean_hv\n",
    "    data_20['med'] = median_hv\n",
    "    data_20['desv'] = std_hv\n",
    "    \n",
    "    data_20 = pd.DataFrame(data_20, index = data_20['config'])\n",
    "    \n",
    "    tablas_20[instance_id] = data_20\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tablas_20['5']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graficar el tiempo de ejecución para todas las instancias de prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if plot_time:\n",
    "    insts = ['4','7','5']\n",
    "    tiempos = dict([i, []] for i in insts)\n",
    "    num_confs = len(configuraciones)\n",
    "    ind = np.arange(num_confs)\n",
    "    \n",
    "    for i in insts:\n",
    "        with open('Results/testPerformance' + i+ '.pkl', 'rb') as f:\n",
    "            testPerformance = pickle.load(f) \n",
    "            tiempos[i] = [testPerformance[j]['time'] for j in range(len(testPerformance))]\n",
    "            f.close()\n",
    "\n",
    "\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(8, 4))\n",
    "    \n",
    "    # Ancho de las barras\n",
    "    ancho_barra = 1\n",
    "    esp = 0.15 # Espacio entre barras\n",
    "\n",
    "    # Dibujar las barras\n",
    "    rects1 = ax.bar(2*ind + ind*3 - 0.5, np.mean(tiempos['4'],axis=1), ancho_barra, label='$Instancia\\ 4\\ (|J|=19)$', color=cmap(0.2), zorder = 2)\n",
    "    rects2 = ax.bar(2*ind + ind*3 + 1 - 0.5, np.mean(tiempos['7'],axis=1), ancho_barra, label='$Instancia\\ 7\\ (|J|=37)$', color=cmap(0.5), zorder = 2)\n",
    "    rects3 = ax.bar(2*ind + ind*3 + 2 - 0.5, np.mean(tiempos['5'],axis=1), ancho_barra, label='$Instancia\\ 5\\ (|J|=53)$', color=cmap(0.8), zorder = 2)\n",
    "\n",
    "    for i in range(num_confs):\n",
    "        ax.text(2*i + i*3 - 0.5, 1.05*np.mean(tiempos['4'],axis=1)[i], f'{np.mean(tiempos[\"4\"],axis=1)[i]:.2f}', \n",
    "                ha='center', va='bottom', color='black', zorder = 3, fontsize=6, rotation=90)\n",
    "        ax.text(2*i + i*3 + 1 - 0.5, 1.05*np.mean(tiempos['7'],axis=1)[i], f'{np.mean(tiempos[\"7\"],axis=1)[i]:.2f}',\n",
    "                ha='center', va='bottom', color='black', zorder = 3, fontsize=6, rotation=90)\n",
    "        ax.text(2*i + i*3 + 2 - 0.5, 1.02*np.mean(tiempos['5'],axis=1)[i], f'{np.mean(tiempos[\"5\"],axis=1)[i]:.2f}',\n",
    "                ha='center', va='bottom', color='black', zorder = 3, fontsize=6, rotation=90)\n",
    "\n",
    "    # ax.plot([-10,100],[np.mean(promedio_info), np.mean(promedio_info)], color=cmap(0.2), linestyle='--', linewidth=1, zorder=2)\n",
    "    # ax.plot([-10,100],[np.mean(promedio_procesos), np.mean(promedio_procesos)], color=cmap(0.5), linestyle='--', linewidth=1, zorder=2)\n",
    "\n",
    "    # Configuración de ejes y etiquetas\n",
    "    ax.set_xlabel('$Configuración$')\n",
    "    ax.set_ylabel('$Tiempo (s)$')\n",
    "    ax.set_title('Tiempo de optimización de las instancias')\n",
    "    ax.set_xticks([i*2 + 3 * i + 0.5 for i in range(len(tiempos['5']))])\n",
    "    ax.set_xticklabels([f'{i+1}' for i in range(len(tiempos['5']))])\n",
    "    ax.set_xlim([-2, 2*(num_confs-1) + 3*(num_confs-1) +3])\n",
    "    ax.set_ylim([0, 1.8*np.max([np.mean(tiempos['4']), np.mean(tiempos['7']), np.mean(tiempos['5'])])])\n",
    "\n",
    "    # Leyenda para identificar los modelos\n",
    "    ax.legend(ncols=3, loc='upper center', fancybox=True, shadow=True)\n",
    "    ax.grid(True,zorder=0, color='gray', linestyle='--', linewidth=0.4)\n",
    "    # Mostrar la gráfica\n",
    "    fig.savefig('/home/cic/Tesis/Figuras/Results/tiemposOptimización.png', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obtiene el historial del frente de Pareto para la mediana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para ejecutar desde cero\n",
    "test = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para paralelizar\n",
    "def optimiza(parameters, save=True, path='Results/', name='resultado',sh=False):\n",
    "    hv,res = exec_algorithm(parameters, returnData=True, timeout=10,sh=sh)\n",
    "    if save:\n",
    "        with open(path+name+'.pkl', 'wb') as f:  \n",
    "                    pickle.dump(res, f)\n",
    "                    f.close()\n",
    "        #print(name, hv, res)\n",
    "    else:\n",
    "        #print(name, hv, res)\n",
    "        return name, hv, res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insts = ['4','7','5']\n",
    "#insts = ['5']\n",
    "medianas = dict([i, []] for i in insts)\n",
    "\n",
    "for i in insts:\n",
    "    with open('Results/testPerformance' + i+ '.pkl', 'rb') as f:\n",
    "        testPerformance = pickle.load(f) \n",
    "        f.close()\n",
    "    \n",
    "    hipervolumenes = [testPerformance[i]['hv'] for i in range(len(testPerformance))]\n",
    "    \n",
    "    mediana = np.argsort(hipervolumenes, axis=1)\n",
    "    mediana = mediana[:,len(mediana[0])//2]\n",
    "    \n",
    "    medianas[i] = mediana\n",
    "    \n",
    "ejec_medianas = dict([i, dict([(j,'') for j in range(len(configuraciones))])] for i in insts)\n",
    "\n",
    "ejecs = []\n",
    "for instance_id in insts:\n",
    "    instance = '../GeoData/Instances/Instance_' + instance_id + '.pkl'\n",
    "    \n",
    "    for i,p in enumerate(configuraciones):\n",
    "        seed = medianas[instance_id][i]*308\n",
    "        \n",
    "        parameters = ' -i ' + instance + ' --seed ' + str(seed) + ' ' + p\n",
    "        ejecs.append([instance_id,i,parameters])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prueba de ejecución en paralelo\n",
    "#test_paralelo = Parallel(n_jobs=3)(delayed(optimiza)(e[2],name=str(e[0])+'_'+str(e[1]),sh=False,save=False) for e in ejecs[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if test:\n",
    "#     Parallel(n_jobs=3)(delayed(optimiza)(e[2],name=str(e[0])+'_'+str(e[1]),sh=True,save=True) for e in ejecs)\n",
    "#resultados = [optimiza(e[0],e[1],e[2]) for e in ejecs]\n",
    "\n",
    "# Verifica la mediana\n",
    "# for i,m in enumerate(medianas['5']):\n",
    "#     print(testPerformance[i]['hv'][m])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convergencia del frente de Pareteo de la mediana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if plot_convergence:\n",
    "    pf_cmap = plt.get_cmap('viridis')\n",
    "\n",
    "    for num,instance_id in enumerate(insts):\n",
    "        instance = '../GeoData/Instances/Instance_' + instance_id + '.pkl'\n",
    "        \n",
    "        \n",
    "        for conf,p in enumerate(configuraciones):\n",
    "        \n",
    "            with open('Results/' + str(instance_id) + '_' + str(conf) + '.pkl', 'rb') as f:\n",
    "                res = pickle.load(f) \n",
    "                f.close()\n",
    "            \n",
    "            instance = '../GeoData/Instances/Instance_' + instance_id + '.pkl'\n",
    "            with open(instance, 'rb') as f:\n",
    "                instance = pickle.load(f) \n",
    "                f.close()\n",
    "            \n",
    "            capacidades = instance['capacidades']\n",
    "            demanda = instance['demanda']\n",
    "            \n",
    "            max_num_bases = np.ceil(len(demanda)/2)\n",
    "            max_f1, max_f2 = [len(demanda)*9000, max_num_bases + 1]\n",
    "\n",
    "            pf = copy(res.F)\n",
    "            pf[:,0] = pf[:,0]/max_f1\n",
    "            pf[:,1] = pf[:,1]/max_f2\n",
    "            pf = pf[pf[:,1].argsort()]\n",
    "            ind = HV(ref_point=[1,1])\n",
    "            print(instance_id,conf,\"HV\", 1-ind(pf))\n",
    "            \n",
    "            fig,axs = plt.subplots(1,1, figsize=(4,4), constrained_layout=True)\n",
    "\n",
    "            transp = lambda x: (0.7,0,0.6,0.1)\n",
    "\n",
    "\n",
    "            for id,r in enumerate(res.history):\n",
    "                i = id/len(res.history)\n",
    "                pfi = copy(r.pop.get(\"F\"))\n",
    "                pfi[:,0] = pfi[:,0]/max_f1\n",
    "                pfi[:,1] = pfi[:,1]/max_f2\n",
    "                \n",
    "                indices_sort = np.argsort(pfi[:, 1])\n",
    "                pfi = pfi[indices_sort]\n",
    "                \n",
    "                viol = copy(r.pop.get(\"CV\"))\n",
    "                viol = viol[indices_sort]\n",
    "                \n",
    "\n",
    "                \n",
    "                colores_relleno = [pf_cmap(i) if j == 0 else transp(pf_cmap(i)) for j in viol]\n",
    "                tamano = [30 if j == 0 else 15 for j in viol]\n",
    "                \n",
    "                axs.scatter(pfi[:, 1]*max_f2, pfi[:, 0]*max_f1, s=tamano, facecolors=colores_relleno, \n",
    "                            edgecolors='none',zorder=2)\n",
    "                \n",
    "\n",
    "                # if id == 0:\n",
    "                #     axs[0].scatter(pfi[:, 1]*max_f2, pfi[:, 0]*max_f1, marker = 'x', color='r',zorder=0, label='Solucion inicial')\n",
    "                \n",
    "            axs.plot(pf[:, 1]*max_f2, pf[:, 0]*max_f1, color='r',zorder=3, lw=0.5, ls='--')\n",
    "            axs.scatter(pf[:, 1]*max_f2, pf[:, 0]*max_f1, color='r',zorder=3, lw=0, s=10,label='Frente final')\n",
    "\n",
    "            axs.set_box_aspect(1)\n",
    "            axs.set_xlabel('$f_2$')\n",
    "            axs.set_ylabel('$f_1$')\n",
    "            axs.set_xlim([0,max_f2])\n",
    "            axs.set_ylim([0,max_f1])\n",
    "            axs.ticklabel_format(axis='y', style='sci', scilimits=(0,0))\n",
    "            step = [1,2][(max_f2 > 20)*1]\n",
    "            axs.set_xticks([i for i in range(0,int(max_f2)+1,step)])\n",
    "            axs.set_title('Instancia ' + instance_id + ' - Configuración ' + str(conf+1))\n",
    "            axs.grid(True,zorder=0, color='gray', linestyle='--', linewidth=0.2)\n",
    "            #axs.legend()\n",
    "            fig.savefig('/home/cic/Tesis/Figuras/Results/pareto_' + instance_id + '_' + str(conf) + '.png', dpi=300)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convergencia del frente de Pareto de las medianas de cada configuración por instancia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "\n",
    "\n",
    "def select_dominated(a,b):\n",
    "    ge = all(map(operator.ge, a[1], b[1]))\n",
    "    le = all(map(operator.le, a[1], b[1]))\n",
    "    # return dominated\n",
    "    return b if le else a if ge else 'indifferent'\n",
    "\n",
    "def paretoFront(a):\n",
    "    b = copy(a)\n",
    "    if len(a) > 1:\n",
    "        for i in range(len(a)):\n",
    "            for j in range(i,len(a)):\n",
    "                if i != j:\n",
    "                    try:\n",
    "                        b.remove(select_dominated(a[i],a[j]))\n",
    "                    except:\n",
    "                        \"\"\n",
    "    return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instance_id ='7'\n",
    "instance = '../GeoData/Instances/Instance_' + instance_id + '.pkl'\n",
    "\n",
    "fig,axs = plt.subplots(1,1, figsize=(4,4), constrained_layout=True)\n",
    "frentes = []\n",
    "\n",
    "for conf,p in enumerate(configuraciones):\n",
    "\n",
    "    with open('Results/' + str(instance_id) + '_' + str(conf) + '.pkl', 'rb') as f:\n",
    "        res = pickle.load(f) \n",
    "        f.close()\n",
    "    \n",
    "    instance = '../GeoData/Instances/Instance_' + instance_id + '.pkl'\n",
    "    with open(instance, 'rb') as f:\n",
    "        instance = pickle.load(f) \n",
    "        f.close()\n",
    "    \n",
    "    capacidades = instance['capacidades']\n",
    "    demanda = instance['demanda']\n",
    "    \n",
    "    max_num_bases = np.ceil(len(demanda)/2)\n",
    "    max_f1, max_f2 = [len(demanda)*9000, max_num_bases + 1]\n",
    "\n",
    "    pf = copy(res.F)\n",
    "    frentes += pf.tolist()\n",
    "    \n",
    "    pf[:,0] = pf[:,0]/max_f1\n",
    "    pf[:,1] = pf[:,1]/max_f2\n",
    "    pf = pf[pf[:,1].argsort()]\n",
    "    ind = HV(ref_point=[1,1])\n",
    "    print(instance_id,conf,\"HV\", 1-ind(pf))\n",
    "    \n",
    "    axs.plot(pf[:, 1]*max_f2, pf[:, 0]*max_f1,zorder=3, lw=1, ls='--')\n",
    "    axs.scatter(pf[:, 1]*max_f2, pf[:, 0]*max_f1,zorder=3, lw=0, s=15,label='Conf.' + str(conf+1))\n",
    "\n",
    "axs.set_box_aspect(1)\n",
    "axs.set_xlabel('$f_2$')\n",
    "axs.set_ylabel('$f_1$')\n",
    "axs.set_xlim([min(np.array(frentes)[:,1])-1,max_f2])\n",
    "axs.set_ylim([min(np.array(frentes)[:,0])-10000,max(np.array(frentes)[:,0])+10000])\n",
    "axs.ticklabel_format(axis='y', style='sci', scilimits=(0,0))\n",
    "step = [1,2][(max_f2 > 20)*1]\n",
    "axs.set_xticks([i for i in range(int(min(np.array(frentes)[:,1])-1),int(max_f2)+1,step)])\n",
    "axs.set_title('Frentes de Pareto, instancia ' + instance_id)\n",
    "axs.grid(True,zorder=0, color='gray', linestyle='--', linewidth=0.2)\n",
    "axs.legend(ncol=2,prop = { \"size\": 8 }, fancybox=True, shadow=True)\n",
    "fig.savefig('/home/cic/Tesis/Figuras/Results/pareto_' + instance_id + '_' + 'all.png', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combinación de frentes de Pareto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if plot_performance_multi:\n",
    "    instance_id ='4'\n",
    "    instance = '../GeoData/Instances/Instance_' + instance_id + '.pkl'\n",
    "\n",
    "    fig,ax = plt.subplots(1,1, figsize=(4,4), constrained_layout=True)\n",
    "    frentes = []\n",
    "\n",
    "    with open('Results/testPerformance' + instance_id + '.pkl', 'rb') as f:\n",
    "            testPerformance = pickle.load(f) \n",
    "            f.close()\n",
    "    hipervolumenes_v = [testPerformance[i]['hv'] for i in range(len(testPerformance))]\n",
    "    resultados = [testPerformance[i]['res'] for i in range(len(testPerformance))]\n",
    "\n",
    "    hv_merge = dict([i, []] for i in range(len(configuraciones)+1))\n",
    "    hv_pf_merge = dict([i, []] for i in range(len(configuraciones)+1))\n",
    "\n",
    "    num_samples = 20\n",
    "\n",
    "    for seed in range(num_samples):\n",
    "\n",
    "        np.random.seed(seed*478)\n",
    "\n",
    "        # Para cada configuración\n",
    "        for conf in range(len(resultados)):\n",
    "            \n",
    "            # Carga la instancia\n",
    "            instance = '../GeoData/Instances/Instance_' + instance_id + '.pkl'\n",
    "            with open(instance, 'rb') as f:\n",
    "                instance = pickle.load(f) \n",
    "                f.close()\n",
    "\n",
    "            # Calcula los valores máximos de las funciones objetivo\n",
    "            demanda = instance['demanda']\n",
    "            max_num_bases = np.ceil(len(demanda)/2)\n",
    "            max_f1, max_f2 = [len(demanda)*9000, max_num_bases + 1]\n",
    "            \n",
    "            # Selecciona 5 ejecuciones al azar\n",
    "            ejecs = np.random.choice(len(resultados[conf]), 5, replace=False)\n",
    "            \n",
    "            # Para cada ejecución seleccionada\n",
    "            frentes_conf = []\n",
    "            for e in ejecs:\n",
    "                \n",
    "                # Selecciona el frente de Pareto\n",
    "                pf = copy(resultados[conf][e].F)\n",
    "                frentes_conf += pf.tolist()\n",
    "            \n",
    "            # Fusiona los frentes de Pareto\n",
    "            frentes_ind = [(ind,vals) for ind,vals in enumerate(frentes_conf)]\n",
    "            merged_ind = paretoFront(frentes_ind)\n",
    "            merged = np.array([frentes_conf[i[0]] for i in merged_ind])\n",
    "            merged = np.array(sorted(merged, key=lambda x: x[1]))\n",
    "            \n",
    "            # Normaliza los valores de las funciones objetivo\n",
    "            pf = copy(merged)\n",
    "            pf[:,0] = pf[:,0]/max_f1\n",
    "            pf[:,1] = pf[:,1]/max_f2\n",
    "            pf = pf[pf[:,1].argsort()]\n",
    "            ind = HV(ref_point=[1,1])\n",
    "            ihv = 1-ind(pf)\n",
    "\n",
    "            # Guarda el valor del hipervolumen\n",
    "            hv_merge[conf].append(ihv)\n",
    "            hv_pf_merge[conf].append((ihv,copy(merged)))\n",
    "            \n",
    "            # # Grafica el frente de Pareto fusionado para esa configuración\n",
    "            # ax.scatter(merged[:,1], merged[:,0], marker='o',zorder=0, lw=0, s=30,\n",
    "            #             label='Conf.' + str(conf+1)+'HV='+str(round(1-ind(pf),3)))\n",
    "            # ax.plot(merged[:,1], merged[:,0], '--',zorder=0, lw=1)\n",
    "        \n",
    "        \n",
    "        conf = len(resultados)\n",
    "            \n",
    "        # Grafica el frente de Pareto fusionado para una ejecución de todas las configuraciones\n",
    "        frentes = []\n",
    "        ejecs = np.random.choice(len(resultados[0]), 5, replace=True)\n",
    "\n",
    "        for i,e in enumerate(ejecs):\n",
    "            pf = copy(resultados[i][e].F)\n",
    "            frentes += pf.tolist()\n",
    "\n",
    "        # Fusiona los frentes de Pareto\n",
    "        frentes_ind = [(ind,vals) for ind,vals in enumerate(frentes)]\n",
    "        merged_ind = paretoFront(frentes_ind)\n",
    "        merged = np.array([frentes[i[0]] for i in merged_ind])\n",
    "        merged = np.array(sorted(merged, key=lambda x: x[1]))\n",
    "\n",
    "        # Normaliza los valores de las funciones objetivo\n",
    "        pf = copy(merged)\n",
    "        pf[:,0] = pf[:,0]/max_f1\n",
    "        pf[:,1] = pf[:,1]/max_f2\n",
    "        pf = pf[pf[:,1].argsort()]\n",
    "        ind = HV(ref_point=[1,1])\n",
    "        ihv = 1-ind(pf)\n",
    "        \n",
    "        # Guarda el valor del hipervolumen\n",
    "        hv_merge[conf].append(ihv)\n",
    "        hv_pf_merge[conf].append((ihv,copy(merged)))\n",
    "\n",
    "\n",
    "        # # Grafica el frente de Pareto fusionado de una ejecución por configuración\n",
    "        # ax.scatter(merged[:,1], merged[:,0], marker=6,zorder=0, lw=0, s=40, color='k',\n",
    "        #             label='1xConf HV='+str(round(1-ind(pf),3)))\n",
    "        # ax.plot(merged[:,1], merged[:,0], '--',zorder=0, lw=1)\n",
    "\n",
    "\n",
    "    for conf in hv_merge.keys():\n",
    "        mediana = np.argsort(hv_merge[conf])[len(hv_merge[conf])//2]\n",
    "        merged = hv_pf_merge[conf][mediana][1]\n",
    "        hv_mediana = hv_pf_merge[conf][mediana][0]\n",
    "        \n",
    "        # Grafica el frente de Pareto fusionado para esa configuración\n",
    "        ax.scatter(merged[:,1], merged[:,0], marker='o',zorder=0, lw=0, s=30, label='Conf.' + str(conf+1)+' HV='+str(round(hv_mediana,5)))\n",
    "        ax.plot(merged[:,1], merged[:,0], '--',zorder=0, lw=1)\n",
    "\n",
    "    ax.set_box_aspect(1)\n",
    "    ax.set_xlabel('$f_2$')\n",
    "    ax.set_ylabel('$f_1$')\n",
    "    ax.set_xlim([min(np.array(frentes_conf)[:,1])-1,max(np.array(frentes_conf)[:,1])+2])\n",
    "    ax.set_ylim([min(np.array(frentes_conf)[:,0])-10000,max(np.array(frentes_conf)[:,0])+50000])\n",
    "    ax.ticklabel_format(axis='y', style='sci', scilimits=(0,0))\n",
    "    step = [1,2][(max(np.array(frentes_conf)[:,1])+2 > 20)*1]\n",
    "    ax.set_xticks([i for i in range(int(min(np.array(frentes_conf)[:,1])-1),int(max(np.array(frentes_conf)[:,1])+2)+1,step)])\n",
    "    ax.set_yticks([i for i in range(int(min(np.array(frentes_conf)[:,0]//1e4)*1e4),\n",
    "                                    int(max(np.array(frentes_conf)[:,0]//1e4 + 10)*1e4),int(0.25e5))])\n",
    "    \n",
    "    ax.set_title('Frentes de Pareto, instancia ' + instance_id)\n",
    "    ax.grid(True,zorder=0, color='gray', linestyle='--', linewidth=0.2)\n",
    "    ax.legend(ncol=2,prop = { \"size\": 8 }, fancybox=True, shadow=True, loc='upper center', fontsize=8)\n",
    "    fig.savefig('/home/cic/Tesis/Figuras/Results/p_merge_' + instance_id + '_' + 'all.png', dpi=300)\n",
    "    fig2, ax2 = plt.subplots(figsize=(3, 8))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # ----------------------------------------------------\n",
    "    # Plot de las cajas de multiples ejecuciones`\n",
    "    # ----------------------------------------------------\n",
    "\n",
    "    # Ejecuciones de otras configuraciones en irace\n",
    "    irace = pd.read_csv('../ajuste/export/export.csv')\n",
    "    irace.pop('Unnamed: 0')\n",
    "\n",
    "    ejecs = irace[irace['instancename'] == 'Instance_' + instance_id]\n",
    "    ejecs = ejecs[ejecs['type']=='regular']\n",
    "    ejecs = ejecs[ejecs['value'] <= 0.99]\n",
    "    bkv = ejecs['bkv'].to_list()[0]\n",
    "\n",
    "    # Coordenadas x para las barras\n",
    "    ind = len(testPerformance)\n",
    "\n",
    "    # Ancho de las barras\n",
    "    ancho_barra = 0.5\n",
    "\n",
    "    hipervolumenes = [hv_merge[i] for i in range(len(hv_merge))]\n",
    "\n",
    "    ax2.boxplot(hipervolumenes,widths=ancho_barra, showfliers=True, zorder = 3, \n",
    "            medianprops=dict(color=(1,0,0,1)), )\n",
    "\n",
    "    old = (0,0,0,0.3)\n",
    "    bp2 = ax2.boxplot(hipervolumenes_v+[],positions= [i+1 for i in range(len(hipervolumenes_v))],\n",
    "                widths=ancho_barra, showfliers=True, zorder = 3, labels=['hh']*len(hipervolumenes_v),\n",
    "                boxprops=dict(color=old, ls='-.'), \n",
    "                medianprops=dict(color=old, ls='-.'),\n",
    "                whiskerprops=dict(color=old, ls = '-.'),\n",
    "                capprops=dict(color=old),\n",
    "                flierprops=dict(color=old, markeredgecolor=old),\n",
    "                )\n",
    "\n",
    "\n",
    "\n",
    "    for i in range(len(hv_merge)):\n",
    "        ax2.scatter([i+1]*len(hv_merge[i] ), hv_merge[i] , \n",
    "                cmap='viridis', marker='x', zorder = 3, alpha=0.2, linewidths=1)\n",
    "\n",
    "    plotbkv = ax2.plot([-1,7], [bkv,bkv], '--', color='black', zorder = 0, label='Mejor valor conocido')\n",
    "\n",
    "    # Configuración de ejes y etiquetas\n",
    "    ax2.set_xlabel('$Configuración$')\n",
    "    ax2.set_ylabel('$Hipervolumen$')\n",
    "    ax2.set_title('$Instancia\\ ' + instance_id + '$')\n",
    "    ax2.set_xticks([i+1 for i in range(len(hv_merge))])\n",
    "    ax2.set_xticklabels([f'{i+1}' for i in range(len(hv_merge))])\n",
    "    ax2.set_xlim([0,7])\n",
    "    ax2.set_ylim([bkv-0.01, np.max(hipervolumenes_v)+0.01])\n",
    "\n",
    "    ax2.legend(fancybox=True, shadow=True)\n",
    "    ax2.legend([bp2['boxes'][0],plotbkv[0]],['Caja previa','Mejor valor conocido'], fancybox=True, shadow=True)\n",
    "    ax2.grid(True,zorder=0, color='gray', linestyle='--', linewidth=0.4)\n",
    "\n",
    "    fig2.savefig('/home/cic/Tesis/Figuras/Results/testPerformance' + instance_id + '_multi.png', dpi=300, bbox_inches='tight')\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int(min(np.array(frentes_conf)[:,0])//1e4)*1e4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frentes_ind = [(ind,vals) for ind,vals in enumerate(frentes)]\n",
    "merged_ind = paretoFront(frentes_ind)\n",
    "merged = np.array([frentes[i[0]] for i in merged_ind])\n",
    "axs.scatter(merged[:,1], merged[:,0], marker=6, color='r',zorder=0, lw=0, s=40,label='Frente combinado')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rapids-pymoo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
